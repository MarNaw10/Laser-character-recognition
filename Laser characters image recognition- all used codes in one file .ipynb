{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01f1e3ac",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c168001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import idx2numpy\n",
    "import imageio\n",
    "from idx_tools import Idx\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ee4487",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is the part for extracting digits from laser images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ba581f",
   "metadata": {},
   "source": [
    "### Part 1 - character images extraction, clustering and converting to Idx format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332ffcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the files \n",
    "import os\n",
    "os.getcwd()\n",
    "collection = \"./Chip_photos\"\n",
    "for i, filename in enumerate(os.listdir(collection)):\n",
    "    os.rename(\"./Chip_photos/\" + filename, \"./Chip_photos/\" + \"Image_\"+ str(i) + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea951f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # Computer vision library\n",
    "import imageio\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Read the color image\n",
    "\n",
    "for image in os.listdir('./Chip_photos/'):\n",
    "    image = cv2.imread(os.path.join('./Chip_photos/', image))\n",
    "    \n",
    "    #new_image = image.copy()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 13, 2)\n",
    "    inverted_binary = ~binary\n",
    "    contours, hierarchy = cv2.findContours(inverted_binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    with_contours = cv2.drawContours(gray, contours, 3,(0,0,255),1)\n",
    "    \n",
    "    \n",
    "    path='./char_7'\n",
    "    n = len(os.listdir('./char_7')) + 1\n",
    "    n_roi = np.shape(contours)[0]\n",
    "   \n",
    "    for c in contours:\n",
    "##for c in range(n_roi):\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        if (cv2.contourArea(c)) > 50:\n",
    "        #cv2.rectangle(with_contours,(x,y), (x+w,y+h), (255,0,0), 1)\n",
    "            cv2.rectangle(image,(x,y), (x+w,y+h), (255,0,0), 1)\n",
    "            ROI = with_contours[y:y+h, x:x+w]\n",
    "        #cv2.imwrite('./char_3/ROI_{}.jpg'.format(ROI_number), ROI)\n",
    "        #imageio.imwrite('{}/char{}.jpg'.format(ROI_number), ROI)\n",
    "            imageio.imwrite('{}/char{}.jpg'.format(path, n), ROI)\n",
    "        #ROI_number += 1\n",
    "            n += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ced7de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is the part for clustering and converting images into idx format for NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d823da0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting some of the images to gray scale to be consistant\n",
    "import cv2\n",
    "import imageio\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "\n",
    "for image in os.listdir('./color_characters/'):\n",
    "    image = cv2.imread(os.path.join('./color_characters/', image))\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    path='./characters_gray'\n",
    "    n = len(os.listdir('./characters_gray')) + 1\n",
    "    imageio.imwrite('{}/char{}.jpg.jpg'.format(path, n), gray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dbf311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the files after converting the rest to thr gray scale\n",
    "import os\n",
    "os.getcwd()\n",
    "collection = \"./all_characters\"\n",
    "for i, filename in enumerate(os.listdir(collection)):\n",
    "    os.rename(\"./all_characters/\" + filename, \"./all_characters/\" + \"char_\"+ str(i) + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961e84e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing, renaming, clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bcaac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bbc247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the individual letters\n",
    "data_path = './all_characters/'\n",
    "\n",
    "# Target image size\n",
    "convSize = [28, 28]\n",
    "\n",
    "# File names of all sample images\n",
    "files = [data_path + x for x in os.listdir(data_path)]\n",
    "\n",
    "# Resize images and append to a numpy array\n",
    "images = []\n",
    "for file in files:\n",
    "    img = cv2.imread(file)[:, :, 0]\n",
    "    img = cv2.resize(img, (convSize[0], convSize[1]))\n",
    "    img = img.reshape(convSize[0] * convSize[1])\n",
    "    images.append(img)\n",
    "    \n",
    "images = np.array(images, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11a7c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1431a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply StandardScaler on the letter data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(images)\n",
    "scaled = scaler.transform(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06ac5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the first 25 principal components\n",
    "pca = PCA(n_components=25)\n",
    "pca.fit(scaled)\n",
    "pca_img = pca.transform(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2383f422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use K-Means clustering to group the data into 100 clusters\n",
    "nClusters = 100\n",
    "kmeans = KMeans(n_clusters=nClusters, random_state=0).fit(pca_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a387535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "\n",
    "ax.scatter(pca_img[:, 0], pca_img[:, 1], pca_img[:, 2], c=kmeans.labels_)\n",
    "\n",
    "ax.set_xlabel('component 1', fontsize=18)\n",
    "ax.set_ylabel('component 2', fontsize=18)\n",
    "ax.set_zlabel('component 3', fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c998aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './clustered'\n",
    "\n",
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "n = 0\n",
    "for i in range(kmeans.labels_.max()):\n",
    "    \n",
    "    cluster_path = '{}/{}'.format(path, i)\n",
    "    \n",
    "    if not os.path.isdir(cluster_path):\n",
    "        os.mkdir(cluster_path)\n",
    "    \n",
    "    tmp = images[kmeans.labels_ == kmeans.labels_[i]]\n",
    "    \n",
    "    for j in range(np.shape(tmp)[0]):\n",
    "        tmpImg = np.reshape(tmp[j], convSize).astype(np.uint8)\n",
    "        imageio.imwrite('{}/{}.jpg'.format(cluster_path, n), tmpImg)\n",
    "        n += 1\n",
    "        \n",
    "# Delete the un-clustered data\n",
    "[os.remove(data_path + x) for x in os.listdir(data_path)]\n",
    "os.rmdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90584b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where is the sorted data located?\n",
    "dataset_path = './data/' \n",
    "\n",
    "# Where should the converted data be stored?\n",
    "dest_folder = './datasetTMP/' \n",
    "\n",
    "# What is the ratio of train vs. test data?\n",
    "train_percent = 0.7\n",
    "\n",
    "# Subfolders for structuring the sorted data\n",
    "train_path = dataset_path + 'train/'\n",
    "test_path = dataset_path + 'test/'\n",
    "\n",
    "# Find all folders in the sorted data\n",
    "folders = os.listdir(dataset_path)\n",
    "\n",
    "# Create folders\n",
    "if not os.path.isdir(train_path):\n",
    "    os.mkdir(train_path)\n",
    "    os.mkdir(test_path)\n",
    "    \n",
    "if not os.path.isdir(dest_folder):\n",
    "    os.mkdir(dest_folder)\n",
    "    \n",
    "# Go through all folders in the sorted data and split into train and test    \n",
    "for char in folders:\n",
    "    char_path = dataset_path + char + '/'\n",
    "    train_folder = train_path + char + '/'\n",
    "    test_folder = test_path + char + '/'\n",
    "    \n",
    "    samples = os.listdir(char_path)\n",
    "    n_samples = len(samples)\n",
    "    n_train = round(train_percent * n_samples)\n",
    "    \n",
    "    sel = np.arange(n_samples)\n",
    "    np.random.shuffle(sel)\n",
    "    \n",
    "    idx_train = sel[0:n_train] \n",
    "    idx_test = sel[n_train:]\n",
    "    \n",
    "    if not os.path.isdir(train_folder):\n",
    "        os.mkdir(train_folder)\n",
    "        \n",
    "    if not os.path.isdir(test_folder):\n",
    "        os.mkdir(test_folder)\n",
    "    \n",
    "    [os.rename(char_path + samples[x], train_folder + samples[x]) for x in idx_train]\n",
    "    [os.rename(char_path + samples[x], test_folder + samples[x]) for x in idx_test]\n",
    "    \n",
    "    os.rmdir(char_path)\n",
    "    \n",
    "# Convert data to idx format    \n",
    "Idx.save_idx(train_path)\n",
    "Idx.save_idx(test_path)\n",
    "\n",
    "# Move converted dataset to target folder\n",
    "os.rename(train_path + 'images.idx3-ubyte', dest_folder + 'train-images.idx3-ubyte')\n",
    "os.rename(train_path + 'labels.idx3-ubyte', dest_folder + 'train-labels.idx3-ubyte')\n",
    "os.rename(test_path + 'images.idx3-ubyte', dest_folder + 'test-images.idx3-ubyte')\n",
    "os.rename(test_path + 'labels.idx3-ubyte', dest_folder + 'test-labels.idx3-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da603b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = os.listdir('./data/train')\n",
    "dest_folder = './datasetTMP/' \n",
    "\n",
    "labelFile = open('{}/labels.txt'.format(dest_folder), \"w\")\n",
    "for char in chars:\n",
    "    \n",
    "    #if char.endswith('_'):\n",
    "        #char = char[:-1].upper()\n",
    "    \n",
    "    # write line to output file\n",
    "    labelFile.write(char)\n",
    "    labelFile.write(\"\\n\")\n",
    "labelFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13bf36f",
   "metadata": {},
   "source": [
    "### Part 2- training neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02524d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(888)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1eb883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import os\n",
    "\n",
    "from time import strftime\n",
    "from PIL import Image \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from IPython.display import display\n",
    "from keras.preprocessing.image import array_to_img\n",
    "\n",
    "from idx_tools import Idx\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa0b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data \n",
    "filename = './dataset/train-images.idx3-ubyte'\n",
    "train_images = Idx.load_idx(filename)\n",
    "\n",
    "# Read the labels\n",
    "filename = './dataset/train-labels.idx3-ubyte'\n",
    "train_labels = Idx.load_labels(filename)\n",
    "\n",
    "# Read the data \n",
    "filename = './dataset/test-images.idx3-ubyte'\n",
    "test_images = Idx.load_idx(filename)\n",
    "\n",
    "# Read the labels\n",
    "filename = './dataset/test-labels.idx3-ubyte'\n",
    "test_labels = Idx.load_labels(filename)\n",
    "\n",
    "# Read the letter names for each label\n",
    "filename = './dataset/labels.txt'\n",
    "\n",
    "file = open(filename,\"r\") \n",
    "class_names =  [str.split(x) for x in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c477015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some random examples\n",
    "n_images = train_images.shape[0]\n",
    "n_plots = 10\n",
    "\n",
    "fig, ax = plt.subplots(1, n_plots, figsize=(18, 18))\n",
    "for i in range(n_plots):\n",
    "    image_num = np.random.randint(low=0, high=n_images)\n",
    "    ax[i].imshow(train_images[image_num], cmap='Greys')\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "    ax[i].set_title(class_names[train_labels[image_num]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6510429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# How many categories do we have in the dataset\n",
    "n_categories = len(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3f3315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the dimensions of each image\n",
    "x_size = train_images.shape[1]\n",
    "y_size = train_images.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafbfc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1d546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d83e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 50\n",
    "\n",
    "img_rows = train_images.shape[1]\n",
    "img_cols = train_images.shape[2]\n",
    "\n",
    "n_categories = len(class_names)\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0], img_rows, img_cols, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "#Creating validation set\n",
    "\n",
    "#validation_size = 10000\n",
    "\n",
    "#x_val = train_images[:validation_size]\n",
    "#y_val = train_labels[:validation_size]\n",
    "\n",
    "#train_images = train_images[validation_size:]\n",
    "#train_labels = train_labels[validation_size:]\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "model_3 = Sequential()\n",
    "model_3.add(Conv2D(32, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model_3.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model_3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_3.add(Dropout(0.5))\n",
    "model_3.add(Flatten())\n",
    "model_3.add(Dense(128, activation='relu'))\n",
    "model_3.add(Dropout(0.3))\n",
    "model_3.add(Dense(80))\n",
    "model_3.add(Dense(n_categories, activation='softmax'))\n",
    "\n",
    "model_3.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.00001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_3 =  model_3.fit(train_images, train_labels,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(test_images, test_labels))\n",
    "\n",
    "score = model_3.evaluate(test_images, test_labels, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cdf4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot the data\n",
    "ax[0].plot(history_3.history['loss'])\n",
    "ax[0].set_title('Loss over epochs', fontsize=23)\n",
    "ax[0].set_xlabel('epoch', fontsize=16)\n",
    "ax[0].set_ylabel('loss', fontsize=16)\n",
    "\n",
    "ax[1].plot(history_3.history['accuracy'])\n",
    "ax[1].set_title('Accuracy over epochs', fontsize=23)\n",
    "ax[1].set_xlabel('epoch', fontsize=16)\n",
    "ax[1].set_ylabel('accuracy', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd137f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "def plot_image(i, predictions_array, true_label, img, category_names):\n",
    "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(category_names[predicted_label],\n",
    "                                         100 * np.max(predictions_array),\n",
    "                                         category_names[true_label]),\n",
    "               color=color)\n",
    "\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label, n_categories):\n",
    "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    this_plot = plt.bar(range(n_categories), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    this_plot[predicted_label].set_color('red')\n",
    "    this_plot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc63807",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], img_rows, img_cols, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "predictions = model_3.predict(test_images)\n",
    "\n",
    "# Read the data \n",
    "filename = './dataset/test-images.idx3-ubyte'\n",
    "test_images = Idx.load_idx(filename)\n",
    "\n",
    "# Read the labels\n",
    "filename = './dataset/test-labels.idx3-ubyte'\n",
    "test_labels = Idx.load_labels(filename)\n",
    "\n",
    "\n",
    "# Plot the first X test images, their predicted label, and the true label\n",
    "# Color correct predictions in blue, incorrect predictions in red\n",
    "num_rows = 15\n",
    "num_cols = 15\n",
    "num_images = num_rows * num_cols\n",
    "plt.figure(figsize=(2 * 2 * num_cols, 2 * num_rows))\n",
    "for i in range(num_images):\n",
    "    rand_image = np.random.randint(low=0, high=test_images.shape[0])\n",
    "    \n",
    "    plt.subplot(num_rows, 2 * num_cols, 2 * i + 1)\n",
    "    \n",
    "    plot_image(rand_image, predictions, test_labels, test_images, class_names)\n",
    "    plt.subplot(num_rows, 2 * num_cols, 2 * i + 2)\n",
    "    plot_value_array(rand_image, predictions, test_labels, n_categories)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b95747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('test_1.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "#test_0 = test_0/255.0\n",
    "#test_0 = cv2.resize(test_0, (28,28))\n",
    "img = np.array(img)\n",
    "img = 255 - img\n",
    "img = img / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f24da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = model_3.predict_classes(img.reshape(-1, 28, 28, 1), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c72e22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_names[result_1[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd8dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('./model_3'):\n",
    "    os.mkdir('./model_3')\n",
    "\n",
    "# Save the model structure to JSON file\n",
    "model_3_json = model_3.to_json()\n",
    "with open(\"./model_3/model_3.json\", \"w\") as json_file:\n",
    "    json_file.write(model_3_json)\n",
    "\n",
    "# Save weights to HDF5 file\n",
    "model_3.save_weights(\"./model_3/model_3.h5\")\n",
    "print(\"Model_3 saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de09da9",
   "metadata": {},
   "source": [
    "### Part 3 - testing the model on real life images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c30a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import load_model\n",
    "from imutils.contours import sort_contours\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "from keras.models import model_from_json\n",
    "\n",
    "print(\"[INFO] loading handwriting OCR model...\")\n",
    "model_path = \"./model_3/model_3.json\"\n",
    "weights_path = \"./model_3/model_3.h5\"\n",
    "# Load the model from file\n",
    "model_conv_file = open(model_path, 'r')\n",
    "model_conv = model_conv_file.read()\n",
    "model_conv = model_from_json(model_conv)\n",
    "model_conv_file.close()\n",
    "# Load the weights from file and add them to the model\n",
    "model_conv.load_weights(weights_path)\n",
    "print(\"ConvNet model and weights loaded\")\n",
    "# Compile the model\n",
    "model_conv.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "#%% \n",
    "filename = './dataset/labels.txt'\n",
    "file = open(filename,\"r\") \n",
    "class_names =  [str.split(x) for x in file.readlines()]\n",
    "\n",
    "# reading image\n",
    "#image = cv2.imread('images\\image_2762.jpg')\n",
    "image = cv2.imread('./Images_5/image_53.jpg')\n",
    "\n",
    "dim = image.shape\n",
    "w1=3*dim[1]/100\n",
    "w2=dim[1]/2\n",
    "h1=3*dim[0]/100\n",
    "h2=dim[0]/2\n",
    "\n",
    "\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "# perform edge detection, find contours in the edge map, and sort the\n",
    "# resulting contours from left-to-right\n",
    "edged = cv2.Canny(blurred, 30, 150)\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,\n",
    "    cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "cnts = sort_contours(cnts, method=\"left-to-right\")[0]\n",
    "# initialize the list of contour bounding boxes and associated\n",
    "# characters that we'll be OCR'ing\n",
    "chars = []\n",
    "#display\n",
    "#cv2.imshow('contours',edged)\n",
    "#cv2.waitKey(0)\n",
    "#%%\n",
    "for c in cnts:\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    if (w >= w1 and w <= w2) and (h >= h1 and h <= h2):\n",
    "    # extract the character and threshold it to make the character\n",
    "    # appear as *white* (foreground) on a *black* background, then\n",
    "   # grab the width and height of the thresholded image\n",
    "       roi = gray[y:y + h, x:x + w]\n",
    "       thresh = cv2.threshold(roi, 0, 255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "        (tH, tW) = thresh.shape\n",
    "    # if the width is greater than the height, resize along the\n",
    "    # width dimension\n",
    "    if tW > tH:\n",
    "        thresh = imutils.resize(thresh, width=28)\n",
    "    # otherwise, resize along the height\n",
    "    else:\n",
    "        thresh = imutils.resize(thresh, height=28)    \n",
    "# re-grab the image dimensions (now that its been resized)\n",
    "# and then determine how much we need to pad the width and\n",
    "# height such that our image will be 32x32\n",
    "        (tH, tW) = thresh.shape\n",
    "        dX = int(max(0, 28 - tW) / 2.0)\n",
    "        dY = int(max(0, 28 - tH) / 2.0)\n",
    "# pad the image and force 32x32 dimensions\n",
    "        padded = cv2.copyMakeBorder(thresh, top=dY, bottom=dY, left=dX, right=dX, borderType=cv2.BORDER_CONSTANT,value=(0, 0, 0))\n",
    "        padded = cv2.resize(padded, (28, 28))\n",
    "    # prepare the padded image for classification via our\n",
    "     # handwriting OCR model\n",
    "        padded = padded.astype(\"float32\") / 255.0\n",
    "        padded = np.expand_dims(padded, axis=-1)\n",
    "     # update our list of characters that will be OCR'd\n",
    "        chars.append((padded, (x, y, w, h)))\n",
    "            \n",
    "            # re-grab the image dimensions (now that its been resized)\n",
    "    # and then determine how much we need to pad the width and\n",
    "    # height such that our image will be 28x28\n",
    "(tH, tW) = thresh.shape\n",
    "dX = int(max(0, 28 - tW) / 2.0)\n",
    "dY = int(max(0, 28 - tH) / 2.0)\n",
    "# pad the image and force 32x32 dimensions\n",
    "padded = cv2.copyMakeBorder(thresh, top=dY, bottom=dY,left=dX, right=dX, borderType=cv2.BORDER_CONSTANT,value=(0, 0, 0))\n",
    "padded = cv2.resize(padded, (28, 28))\n",
    "# prepare the padded image for classification via our\n",
    "# handwriting OCR model\n",
    "padded = padded.astype(\"float32\") / 255.0\n",
    "padded = np.expand_dims(padded, axis=-1)\n",
    "# update our list of characters that will be OCR'd\n",
    "chars.append((padded, (x, y, w, h)))\n",
    "            \n",
    "# extract the bounding box locations and padded characters\n",
    "boxes = [b[1] for b in chars]\n",
    "chars = np.array([c[0] for c in chars], dtype=\"float32\")\n",
    "# OCR the characters using our handwriting recognition model\n",
    "preds = model_conv.predict(chars)\n",
    "# define the list of label names\n",
    "labelNames = \"0123456789\"\n",
    "labelNames += \"ABCDEFGHJKLMN\"\n",
    "labelNames = [l for l in labelNames]\n",
    "\n",
    "\n",
    "#%%\n",
    "# loop over the predictions and bounding box locations together\n",
    "results=[]\n",
    "count = 0\n",
    "r=0\n",
    "for (pred, (x, y, w, h)) in zip(preds, boxes):\n",
    "    r=h/w\n",
    "    if r>=1.3 and r<=3:\n",
    " # find the index of the label with the largest corresponding  \n",
    " # probability, then extract the probability and label\n",
    "        i = np.argmax(pred)\n",
    "        prob = pred[i]\n",
    "        label = labelNames[i]\n",
    "        print(\"[INFO] {} - {:.2f}% - {:.2f} - x:{:.2f} - y:{:.2f}\".format(label, prob * 100, (h/w), x, y))\n",
    "        \n",
    "        results.append([label,prob,(h/w),x,y,(x+y)])\n",
    "        count = count+1\n",
    "    \n",
    "#if prob >= 0.99:\n",
    " # draw the prediction on the image\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(image, label, (x - 10, y - 10),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)\n",
    "       \n",
    "\n",
    " #now get best guess by taking 4 highest %\n",
    "results.sort(key=lambda results:results[1])\n",
    "results.reverse()\n",
    "answers = results[0:8]\n",
    "answers.sort(key=lambda answers:answers[2])\n",
    "\n",
    "final_answers =[]\n",
    "for l in answers:\n",
    "    if l not in final_answers:\n",
    "        final_answers.append(l)\n",
    "final_answers.sort(key=lambda final_answers:final_answers[5])\n",
    "just_names = [item[0] for item in final_answers]\n",
    "print('Final Answer: '+''.join(just_names[0:2])+'_'+''.join(just_names[2:4]))\n",
    "\n",
    "\n",
    "# show the image\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
